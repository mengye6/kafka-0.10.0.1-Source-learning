### 基本概念
1.Kafka 生产者 KafkaProducer 主要肩负着接收用户自定义消息（这里的消息指代往 kafka 发送的各类数据），并投递给目标 topic 分区的职责。

2.在设计上为了提升消息吞吐量，降低与服务端交互的压力，每次发送消息的请求并非是直接与 kafka 集群进行交互，而是一个异步的过程。

3.当调用 KafkaProducer#send 方法发送消息时，实际上只是将消息缓存到了本地的消息收集器中，Kafka 定义了一个 RecordAccumulator收集器用于收集用户提交的消息数据，同时又在后台维护了一个 sender 线程，以异步的方式循环将收集器中缓存的消息定期定量地投递给 kafka 集群。

###  KafkaProducer 使用示例

1.示例中发送消息依赖于 KafkaProducer 对象，KafkaProducer 类也是我们分析生产者运行机制的入口。创建该对象时我们需要指定 kafka集群地址，以及消息 key 和 value 的序列化器，但是客户端 ID 不是必须指定的，后面在分析源码时会看到如果未明确指定客户端 ID，Kafka 会自动为当前客户端创建一个。

```java
 public class Producer extends Thread {
     private final KafkaProducer<Integer, String> producer;
     private final String topic;
     private final Boolean isAsync;
 
     public Producer(String topic, Boolean isAsync) {
         Properties props = new Properties();
         props.put("bootstrap.servers", "localhost:9092");
         props.put("client.id", "DemoProducer");
         props.put("key.serializer", "org.apache.kafka.common.serialization.IntegerSerializer");
         props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
         producer = new KafkaProducer<>(props);
         this.topic = topic;
         this.isAsync = isAsync;
     }
 
     public void run() {
         int messageNo = 1;
         while (true) {
             String messageStr = "Message_" + messageNo;
             long startTime = System.currentTimeMillis();
             if (isAsync) { // Send asynchronously
                 producer.send(new ProducerRecord<>(topic,
                     messageNo,
                     messageStr), new DemoCallBack(startTime, messageNo, messageStr));
             } else { // Send synchronously
                 try {
                     producer.send(new ProducerRecord<>(topic,
                         messageNo,
                         messageStr)).get();
                     System.out.println("Sent message: (" + messageNo + ", " + messageStr + ")");
                 } catch (InterruptedException | ExecutionException e) {
                     e.printStackTrace();
                 }
             }
             ++messageNo;
         }
     }
 }
 
 class DemoCallBack implements Callback {
 
     private final long startTime;
     private final int key;
     private final String message;
 
     public DemoCallBack(long startTime, int key, String message) {
         this.startTime = startTime;
         this.key = key;
         this.message = message;
     }
     public void onCompletion(RecordMetadata metadata, Exception exception) {
         long elapsedTime = System.currentTimeMillis() - startTime;
         if (metadata != null) {
             System.out.println(
                 "message(" + key + ", " + message + ") sent to partition(" + metadata.partition() +
                     "), " +
                     "offset(" + metadata.offset() + ") in " + elapsedTime + " ms");
         } else {
             exception.printStackTrace();
         }
     }
 }
```

2.接着我们可以调用 KafkaProducer#send 方法向 kafka 集群特定的 topic 投递消息。消息在被投递之前需要封装成 ProducerRecord对象，该对象封装了当前消息的目标 topic、目标分区，key、value，以及时间戳信息。ProducerRecord 的字段定义如下：
```java
    public class ProducerRecord<K, V> {
    
        /** 主题 */
        private final String topic;
        /** 分区 */
        private final Integer partition;
        /** 消息对应的 key */
        private final K key;
        /** 消息内容 */
        private final V value;
        /** 时间戳 */
        private final Long timestamp;
    
        // ... 省略方法定义
    
    }
```
3.示例中我们定义了 isAsync 参数，需要说明的一点是，isAsync 参数虽然表面意思是指以异步的方式发送消息，但是本质上不管该参数如何设置，Kafka 都只有一种消息发送的方式，即异步发送。参数 isAsync 设置为 true 或者 false 的的意义在于指定如何获取消息发送的响应结果，区别在于：
  isAsync=false：以异步方式发送消息，但是通过 future 模式阻塞等待消息的发送的响应结果。
  isAsync=true：以异步方式发送消息，但是通过 callback 模式异步获取消息发送的响应结果，即不管消息发送成功还是失败，都会以回调的方式通知客户端，客户端期间不需要阻塞等待。
 
###  消息收集与发送过程分析

在具体开始分析消息的发送过程之前，我们需要明确 消息发送是一个异步的过程，该过程涉及到 2 个线程的协同工作，其中 1 个线程将待发送的消息写入缓冲区（即收集待发送消息），另外 1 个线程（Sender 线程）负责定期定量将缓冲区中的数据投递给 kafka 集群，并反馈投递结果。

#### 收集待发送的消息
+ KafkaProducer 的字段定义与构造方法

```java
    public class KafkaProducer<K, V> implements Producer<K, V> {
    
        /** clientId 生成器，如果没有明确指定客户端 ID，则使用该字段顺序生成一个 */
        private static final AtomicInteger PRODUCER_CLIENT_ID_SEQUENCE = new AtomicInteger(1);
        /** 生产者唯一标识（对应 client.id 属性配置 ） */
        private String clientId;
        /** 分区选择器（对应 partitioner.class 属性配置），如果未明确指定分区，则基于一定的策略为消息选择合适的分区 */
        private final Partitioner partitioner;
        /** 消息的最大长度（对应 max.request.size 配置，包含消息头、序列化之后的 key 和 value） */
        private final int maxRequestSize;
        /** 发送单条消息的缓冲区大小（对应 buffer.memory 配置） */
        private final long totalMemorySize;
        /** kafka 集群元数据 */
        private final Metadata metadata;
        /** 消息收集器，用于收集并缓存消息，等待 Sender 线程的发送 */
        private final RecordAccumulator accumulator;
        /** 消息发送线程对象 */
        private final Sender sender;
        /** 消息发送线程 */
        private final Thread ioThread;
        /** 压缩算法（对应 compression.type 配置） */
        private final CompressionType compressionType;
        /** 时间戳工具 */
        private final Time time;
        /** key 序列化器（对应 key.serializer 配置） */
        private final Serializer<K> keySerializer;
        /** value 序列化器（对应 value.serializer 配置） */
        private final Serializer<V> valueSerializer;
        /** 封装配置信息 */
        private final ProducerConfig producerConfig;
        /** 等待更新 kafka 集群元数据的最大时长 */
        private final long maxBlockTimeMs;
        /** 消息发送的超时时间（从发送到收到 ACK 响应） */
        private final int requestTimeoutMs;
        /** 发送拦截器（对应 interceptor.classes 配置），用于待发送的消息进行拦截并修改，也可以对 ACK 响应进行拦截处理 */
        private final ProducerInterceptors<K, V> interceptors;
    
        // ... 省略方法定义
    
    }
```
接下来继续看一下 KafkaProducer 类对象的构造过程，KafkaProducer 提供了多个重载的构造方法，这里来看一下最底层的构造方法：

