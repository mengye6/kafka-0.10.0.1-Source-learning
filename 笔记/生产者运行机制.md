### 基本概念
1.Kafka 生产者 KafkaProducer 主要肩负着接收用户自定义消息（这里的消息指代往 kafka 发送的各类数据），并投递给目标 topic 分区的职责。

2.在设计上为了提升消息吞吐量，降低与服务端交互的压力，每次发送消息的请求并非是直接与 kafka 集群进行交互，而是一个异步的过程。

3.当调用 KafkaProducer#send 方法发送消息时，实际上只是将消息缓存到了本地的消息收集器中，Kafka 定义了一个 RecordAccumulator收集器用于收集用户提交的消息数据，同时又在后台维护了一个 sender 线程，以异步的方式循环将收集器中缓存的消息定期定量地投递给 kafka 集群。

在本篇文章中，我们首先来回忆一下 KafkaProducer 的使用方式，然后重点分析消息的收集、缓存、投递，以及响应过程。

###  KafkaProducer 使用示例

1.示例中发送消息依赖于 KafkaProducer 对象，KafkaProducer 类也是我们分析生产者运行机制的入口。创建该对象时我们需要指定 kafka集群地址，以及消息 key 和 value 的序列化器，但是客户端 ID 不是必须指定的，后面在分析源码时会看到如果未明确指定客户端 ID，Kafka 会自动为当前客户端创建一个。

```java
 public class Producer extends Thread {
     private final KafkaProducer<Integer, String> producer;
     private final String topic;
     private final Boolean isAsync;
 
     public Producer(String topic, Boolean isAsync) {
         Properties props = new Properties();
         props.put("bootstrap.servers", "localhost:9092");
         props.put("client.id", "DemoProducer");
         props.put("key.serializer", "org.apache.kafka.common.serialization.IntegerSerializer");
         props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
         producer = new KafkaProducer<>(props);
         this.topic = topic;
         this.isAsync = isAsync;
     }
 
     public void run() {
         int messageNo = 1;
         while (true) {
             String messageStr = "Message_" + messageNo;
             long startTime = System.currentTimeMillis();
             if (isAsync) { // Send asynchronously
                 producer.send(new ProducerRecord<>(topic,
                     messageNo,
                     messageStr), new DemoCallBack(startTime, messageNo, messageStr));
             } else { // Send synchronously
                 try {
                     producer.send(new ProducerRecord<>(topic,
                         messageNo,
                         messageStr)).get();
                     System.out.println("Sent message: (" + messageNo + ", " + messageStr + ")");
                 } catch (InterruptedException | ExecutionException e) {
                     e.printStackTrace();
                 }
             }
             ++messageNo;
         }
     }
 }
 
 class DemoCallBack implements Callback {
 
     private final long startTime;
     private final int key;
     private final String message;
 
     public DemoCallBack(long startTime, int key, String message) {
         this.startTime = startTime;
         this.key = key;
         this.message = message;
     }
     public void onCompletion(RecordMetadata metadata, Exception exception) {
         long elapsedTime = System.currentTimeMillis() - startTime;
         if (metadata != null) {
             System.out.println(
                 "message(" + key + ", " + message + ") sent to partition(" + metadata.partition() +
                     "), " +
                     "offset(" + metadata.offset() + ") in " + elapsedTime + " ms");
         } else {
             exception.printStackTrace();
         }
     }
 }
```

2.接着我们可以调用 KafkaProducer#send 方法向 kafka 集群特定的 topic 投递消息。消息在被投递之前需要封装成 ProducerRecord对象，该对象封装了当前消息的目标 topic、目标分区，key、value，以及时间戳信息。ProducerRecord 的字段定义如下：
```java
    public class ProducerRecord<K, V> {
    
        /** 主题 */
        private final String topic;
        /** 分区 */
        private final Integer partition;
        /** 消息对应的 key */
        private final K key;
        /** 消息内容 */
        private final V value;
        /** 时间戳 */
        private final Long timestamp;
    
        // ... 省略方法定义
    
    }
```
3.示例中我们定义了 isAsync 参数，需要说明的一点是，isAsync 参数虽然表面意思是指以异步的方式发送消息，但是本质上不管该参数如何设置，Kafka 都只有一种消息发送的方式，即异步发送。参数 isAsync 设置为 true 或者 false 的的意义在于指定如何获取消息发送的响应结果，区别在于：
  - isAsync=false：以异步方式发送消息，但是通过 future 模式阻塞等待消息的发送的响应结果。
  - isAsync=true：以异步方式发送消息，但是通过 callback 模式异步获取消息发送的响应结果，即不管消息发送成功还是失败，都会以回调的方式通知客户端，客户端期间不需要阻塞等待。
 
###  消息收集与发送过程分析

在具体开始分析消息的发送过程之前，我们需要明确 消息发送是一个异步的过程，该过程涉及到 2 个线程的协同工作，其中 1 个线程将待发送的消息写入缓冲区（即收集待发送消息），另外 1 个线程（Sender 线程）负责定期定量将缓冲区中的数据投递给 kafka 集群，并反馈投递结果。

#### 收集待发送的消息

+ KafkaProducer 的字段定义与构造方法

```java
    public class KafkaProducer<K, V> implements Producer<K, V> {
    
        /** clientId 生成器，如果没有明确指定客户端 ID，则使用该字段顺序生成一个 */
        private static final AtomicInteger PRODUCER_CLIENT_ID_SEQUENCE = new AtomicInteger(1);
        /** 生产者唯一标识（对应 client.id 属性配置 ） */
        private String clientId;
        /** 分区选择器（对应 partitioner.class 属性配置），如果未明确指定分区，则基于一定的策略为消息选择合适的分区 */
        private final Partitioner partitioner;
        /** 消息的最大长度（对应 max.request.size 配置，包含消息头、序列化之后的 key 和 value） */
        private final int maxRequestSize;
        /** 发送单条消息的缓冲区大小（对应 buffer.memory 配置） */
        private final long totalMemorySize;
        /** kafka 集群元数据 */
        private final Metadata metadata;
        /** 消息收集器，用于收集并缓存消息，等待 Sender 线程的发送 */
        private final RecordAccumulator accumulator;
        /** 消息发送线程对象 */
        private final Sender sender;
        /** 消息发送线程 */
        private final Thread ioThread;
        /** 压缩算法（对应 compression.type 配置） */
        private final CompressionType compressionType;
        /** 时间戳工具 */
        private final Time time;
        /** key 序列化器（对应 key.serializer 配置） */
        private final Serializer<K> keySerializer;
        /** value 序列化器（对应 value.serializer 配置） */
        private final Serializer<V> valueSerializer;
        /** 封装配置信息 */
        private final ProducerConfig producerConfig;
        /** 等待更新 kafka 集群元数据的最大时长 */
        private final long maxBlockTimeMs;
        /** 消息发送的超时时间（从发送到收到 ACK 响应） */
        private final int requestTimeoutMs;
        /** 发送拦截器（对应 interceptor.classes 配置），用于待发送的消息进行拦截并修改，也可以对 ACK 响应进行拦截处理 */
        private final ProducerInterceptors<K, V> interceptors;
    
        // ... 省略方法定义
    
    }
```
接下来继续看一下 KafkaProducer 类对象的构造过程，KafkaProducer 提供了多个重载的构造方法，这里来看一下最底层的构造方法：

```java
private KafkaProducer(ProducerConfig config, Serializer<K> keySerializer, Serializer<V> valueSerializer) {
    try {
        log.trace("Starting the Kafka producer");
        // 获取用户配置信息
        Map<String, Object> userProvidedConfigs = config.originals();
        this.producerConfig = config;
        this.time = Time.SYSTEM;

        // 尝试获取用户配置的 clientId，如果未配置则基于 PRODUCER_CLIENT_ID_SEQUENCE 顺序生成一个
        this.clientId = config.getString(ProducerConfig.CLIENT_ID_CONFIG);
        if (clientId.length() <= 0) {
            // 用户未指定 clientId，基于 PRODUCER_CLIENT_ID_SEQUENCE 顺序生成一个
            clientId = "producer-" + PRODUCER_CLIENT_ID_SEQUENCE.getAndIncrement();
        }

        // ... 省略打点相关注册逻辑

        // 获取配置的分区器对象（反射创建）
        this.partitioner = config.getConfiguredInstance(ProducerConfig.PARTITIONER_CLASS_CONFIG, Partitioner.class);
        // 获取生产者重试间隔
        long retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);

        // 如果参数未指定 key 序列化器，则尝试从配置中获取 key 序列化器对象（反射创建）
        if (keySerializer == null) {
            this.keySerializer = config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, Serializer.class);
            this.keySerializer.configure(config.originals(), true);
        } else {
            config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);
            this.keySerializer = keySerializer;
        }

        // 如果参数未指定 value 序列化器，则尝试从配置中获取 value 序列化器对象（反射创建）
        if (valueSerializer == null) {
            this.valueSerializer = config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, Serializer.class);
            this.valueSerializer.configure(config.originals(), false);
        } else {
            config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);
            this.valueSerializer = valueSerializer;
        }

        // load interceptors and make sure they get clientId
        userProvidedConfigs.put(ProducerConfig.CLIENT_ID_CONFIG, clientId);

        // 获取注册的拦截器列表
        List<ProducerInterceptor<K, V>> interceptorList = (List) (new ProducerConfig(userProvidedConfigs, false))
                .getConfiguredInstances(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ProducerInterceptor.class);
        this.interceptors = interceptorList.isEmpty() ? null : new ProducerInterceptors<>(interceptorList);

        ClusterResourceListeners clusterResourceListeners =
                this.configureClusterResourceListeners(keySerializer, valueSerializer, interceptorList, reporters);

        // 创建并更新 kafka 集群的元数据信息
        this.metadata = new Metadata(retryBackoffMs, config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG), true, clusterResourceListeners);
        // 获取并设置生产者发送请求的大小
        this.maxRequestSize = config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG);
        // 获取并设置生产者内存缓冲区大小，用于缓存要发送到服务器的消息
        this.totalMemorySize = config.getLong(ProducerConfig.BUFFER_MEMORY_CONFIG);
        // 获取并设置消息压缩算法，可以设置为 snappy、gzip 或 lz4，默认不压缩。
        this.compressionType = CompressionType.forName(config.getString(ProducerConfig.COMPRESSION_TYPE_CONFIG));

        // ... 基于用户配置设置 maxBlockTimeMs 和 requestTimeoutMs，省略

        // 创建消息收集器，用于异步发送消息
        this.accumulator = new RecordAccumulator(
                config.getInt(ProducerConfig.BATCH_SIZE_CONFIG), // 指定每个批次的大小（单位：字节）
                this.totalMemorySize,
                this.compressionType,
                config.getLong(ProducerConfig.LINGER_MS_CONFIG), // 消息缓存超时发送时间
                retryBackoffMs,
                metrics,
                time);

        // 获取 kafka 集群主机列表
        List<InetSocketAddress> addresses = ClientUtils.parseAndValidateAddresses(config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG));
        // 更新 kafka 集群元数据信息
        this.metadata.update(Cluster.bootstrap(addresses), Collections.<String>emptySet(), time.milliseconds());
        ChannelBuilder channelBuilder = ClientUtils.createChannelBuilder(config.values());
        // 创建 NetworkClient 对象，NetworkClient 是 producer 网络 I/O 的核心
        NetworkClient client = new NetworkClient(
                new Selector(config.getLong(ProducerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG), metrics, time, "producer", channelBuilder),
                metadata,
                clientId,
                config.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION),
                config.getLong(ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG),
                config.getInt(ProducerConfig.SEND_BUFFER_CONFIG),
                config.getInt(ProducerConfig.RECEIVE_BUFFER_CONFIG),
                requestTimeoutMs,
                time,
                true);

        // 创建并启动 Sender 线程
        this.sender = new Sender(
                client,
                metadata,
                accumulator,
                config.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION) == 1,
                config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG),
                (short) parseAcks(config.getString(ProducerConfig.ACKS_CONFIG)),
                config.getInt(ProducerConfig.RETRIES_CONFIG),
                metrics,
                Time.SYSTEM,
                requestTimeoutMs);
        String ioThreadName = "kafka-producer-network-thread" + (clientId.length() > 0 ? " | " + clientId : "");
        this.ioThread = new KafkaThread(ioThreadName, this.sender, true);
        this.ioThread.start();

        // 打印未使用的配置
        config.logUnused();
        AppInfoParser.registerAppInfo(JMX_PREFIX, clientId);
        log.debug("Kafka producer started");
    } catch (Throwable t) {
        // ... 省略异常处理
    }
}
```

#### 消息收集的过程

了解了 KafkaProducer 的字段定义和对象的构造过程之后，下面正式开始对消息收集的过程进行分析，相关实现位于 KafkaProducer#send 方法中：

```java
public Future<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback) {
    // 遍历注册的拦截器对待发送的消息执行拦截修改
    ProducerRecord<K, V> interceptedRecord = this.interceptors == null ? record : this.interceptors.onSend(record);
    // 调用 doSend 方法开始发送消息
    return this.doSend(interceptedRecord, callback);
}
```

该方法只是简单应用了注册的 producer 拦截器对发送的消息进行拦截修改，而具体消息收集的过程则封装在 KafkaProducer#doSend 方法中。先来看一下 producer 拦截器 ProducerInterceptor 接口的定义：

```java
public interface ProducerInterceptor<K, V> extends Configurable {

    ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);

    void onAcknowledgement(RecordMetadata metadata, Exception exception);

    void close();
}
```

其中，方法 ProducerInterceptor#onSend 用于对待发送的消息进行前置拦截，具体的拦截时机是在消息被序列化和分配分区（如果未手动指定分区）之前，如上述 KafkaProducer#send 方法所示。方法 ProducerInterceptor#onAcknowledgement 用于对已发送到 kafka 集群并得到确认的消息，以及发送失败的消息进行后置拦截，具体的拦截时机是在回调用户自定义的 callback 逻辑之前。

下面继续来看一下收集消息的过程，实现位于 KafkaProducer#doSend 方法中：

```java
private Future<RecordMetadata> doSend(ProducerRecord<K, V> record, Callback callback) {
    TopicPartition tp = null;
    try {
        // 1. 获取 kafka 集群元数据信息，如果当前请求的是新 topic，或者指定的分区超过已知的分区范围，则会触发更新集群元数据信息
        ClusterAndWaitTime clusterAndWaitTime = this.waitOnMetadata(record.topic(), record.partition(), maxBlockTimeMs);
        long remainingWaitMs = Math.max(0, maxBlockTimeMs - clusterAndWaitTime.waitedOnMetadataMs);
        Cluster cluster = clusterAndWaitTime.cluster;

        // 2 基于注册的序列化器对 key 执行序列化
        byte[] serializedKey;
        try {
            serializedKey = keySerializer.serialize(record.topic(), record.key());
        } catch (ClassCastException cce) {
            throw new SerializationException("Can't convert key of class " + record.key().getClass().getName() +
                    " to class " + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() + " specified in key.serializer");
        }

        // 3. 基于注册的序列化器对 value 执行序列化
        byte[] serializedValue;
        try {
            serializedValue = valueSerializer.serialize(record.topic(), record.value());
        } catch (ClassCastException cce) {
            throw new SerializationException("Can't convert value of class " + record.value().getClass().getName() +
                    " to class " + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() + " specified in value.serializer");
        }

        // 4. 为当前消息选择合适的分区，如果未明确指定的话，则基于注册的分区器为当前消息计算分区
        int partition = this.partition(record, serializedKey, serializedValue, cluster);

        /* 5. 将消息追加到消息收集器（RecordAccumulator）中 */

        // 计算当前消息大小，并校验消息是否过大
        int serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);
        this.ensureValidRecordSize(serializedSize);
        tp = new TopicPartition(record.topic(), partition); // 消息投递的目标 topic 分区
        // 如果未明确为当前消息指定时间戳，则设置为当前时间戳
        long timestamp = record.timestamp() == null ? time.milliseconds() : record.timestamp();
        log.trace("Sending record {} with callback {} to topic {} partition {}", record, callback, record.topic(), partition);
        // producer callback will make sure to call both 'callback' and interceptor callback
        Callback interceptCallback = this.interceptors == null ? callback : new InterceptorCallback<>(callback, this.interceptors, tp);
        // 追加消息到收集器中
        RecordAccumulator.RecordAppendResult result = accumulator.append(
                tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);

        /* 6. 条件性唤醒消息发送线程 */

        // 如果队列中不止一个 RecordBatch，或者最后一个 RecordBatch 满了，或者有创建新的 RecordBatch，则唤醒 Sender 线程发送消息
        if (result.batchIsFull || result.newBatchCreated) {
            log.trace("Waking up the sender since topic {} partition {} is either full or getting a new batch", record.topic(), partition);
            // 唤醒 sender 线程，发送消息
            this.sender.wakeup();
        }
        return result.future;
    }
    // ... 省略异常处理
}
```

我们可以将消息的发送过程概括为以下 6 个步骤：

1. 获取集群的元数据（Metadata）信息，如果请求的是新 topic，或者指定的分区 ID 超过了已知的合法区间，则触发更新本地缓存的集群元数据信息。

KafkaProducer 本地会缓存集群的元数据信息，当客户端向集群投递消息时实际上是投递到了目标 topic 指定分区的 leader 副本上。因为集群状态是动态变化的，leader 副本所在的网络位置也会发生迁移，所以客户端在投递消息之前，需要确保本地所缓存的集群信息是最新的，否则需要标记当前集群信息需要更新，具体的更新操作由 sender 线程完成。

KafkaProducer 在发送消息之前会先调用 KafkaProducer#waitOnMetadata 方法获取集群元数据信息，如果感知到本地缓存的集群元数据信息已经过期，则会通知 sender 线程进行更新。首先来看一下保存集群元数据信息的 Metadata 类的字段定义：

```java
public final class Metadata {

    /** 元数据最小更新时间间隔，默认是 100 毫秒，防止更新太频繁 */
    private final long refreshBackoffMs;
    /** 元数据更新时间间隔，默认为 5 分钟 */
    private final long metadataExpireMs;
    /** 元数据版本号，每更新成功一次则版本号加 1 */
    private int version;
    /** 上一次更新元数据的时间戳，不管成功还是失败 */
    private long lastRefreshMs;
    /** 上一次成功更新元数据的时间戳 */
    private long lastSuccessfulRefreshMs;
    /** 集群信息 */
    private Cluster cluster;
    /** 标记是否需要更新集群元数据信息 */
    private boolean needUpdate;
    /** 记录集群中所有的 topic 信息，key 是 topic，value 是 topic 过期的时间戳 */
    private final Map<String, Long> topics;
    /** 元数据更新监听器 */
    private final List<Listener> listeners;
    /** 标记是否需要更新所有 topic 的元数据信息，一般只更新当前用到的 topic 的元数据信息 */
    private boolean needMetadataForAllTopics;
    /** 是否允许 topic 过期 */
    private final boolean topicExpiryEnabled;

    // ... 省略方法定义

}
```

上述方法首先会尝试将当前 topic 加入到本地缓存的 topic 集合中，因为客户端对于 topic 会有一个过期机制，对于长时间未使用的 topic 会从本地缓存中移除。这里一开始调用 Metadata#add 方法除了标记当前 topic 是活跃的之外，另外一个目的在于判断本地是否有该 topic 的缓存信息，如果没有则需要通知 sender 线程更新集群元数据信息。通知的过程实际上只是简单将 Metadata#needUpdate 字段设置为 true，Sender 线程会检查该字段以更新集群元数据信息。

下面继续来看一下 KafkaProducer#waitOnMetadata 方法的实现：

```java
private ClusterAndWaitTime waitOnMetadata(String topic, Integer partition, long maxWaitMs) throws InterruptedException {
    // 添加 topic 到集合中，如果是新 topic，标记需要更新集群元数据信息
    metadata.add(topic);
    // 获取当前集群信息
    Cluster cluster = metadata.fetch();
    // 获取指定 topic 的分区数目
    Integer partitionsCount = cluster.partitionCountForTopic(topic);

    // 如果参数未指定分区，或指定的分区在当前记录的分区范围之内，则返回历史集群信息
    if (partitionsCount != null && (partition == null || partition < partitionsCount)) {
        return new ClusterAndWaitTime(cluster, 0);
    }

    /* 否则，当前缓存的集群元数据信息可能已经过期，需要进行更新 */

    long begin = time.milliseconds();
    long remainingWaitMs = maxWaitMs; // 剩余等待时间
    long elapsed;

    /* 请求集群的元数据信息，直到获取到信息或者超时 */
    do {
        log.trace("Requesting metadata update for topic {}.", topic);
        // 更新 Metadata 的 needUpdate 字段，并获取当前元数据的版本号
        int version = metadata.requestUpdate();
        // 唤醒 sender 线程，由 sender 线程负责更新元数据信息
        sender.wakeup();
        try {
            // 等待元数据更新完成
            metadata.awaitUpdate(version, remainingWaitMs);
        } catch (TimeoutException ex) {
            // 等待超时
            throw new TimeoutException("Failed to update metadata after " + maxWaitMs + " ms.");
        }

        // 获取更新后的集群信息
        cluster = metadata.fetch();
        elapsed = time.milliseconds() - begin;
        if (elapsed >= maxWaitMs) {
            // 等待超时
            throw new TimeoutException("Failed to update metadata after " + maxWaitMs + " ms.");
        }
        // 权限检测
        if (cluster.unauthorizedTopics().contains(topic)) {
            throw new TopicAuthorizationException(topic);
        }
        remainingWaitMs = maxWaitMs - elapsed; // 更新剩余等待时间
        partitionsCount = cluster.partitionCountForTopic(topic); // 获取指定 topic 的分区数目
    } while (partitionsCount == null); // 更新集群信息失败，继续重试

    /* 更新集群信息成功 */

    // 参数指定的分区非法
    if (partition != null && partition >= partitionsCount) {
        throw new KafkaException(String.format("Invalid partition given with record: %d is not in the range [0...%d).", partition, partitionsCount));
    }

    return new ClusterAndWaitTime(cluster, elapsed);
}
```

接下来会调用 Metadata#fetch 方法获取集群信息 Cluster 对象，Cluster 类是对集群节点、topic、分区等信息的一个封装，其字段定义如下：

```java
public final class Cluster {

    /** kafka 集群中的节点信息列表（包括 id、host、port 等信息） */
    private final List<Node> nodes;
    /** 未授权的 topic 集合 */
    private final Set<String> unauthorizedTopics;
    /** 内部 topic 集合 */
    private final Set<String> internalTopics;
    /** 记录 topic 分区与分区详细信息的映射关系 */
    private final Map<TopicPartition, PartitionInfo> partitionsByTopicPartition;
    /** 记录 topic 及其分区信息的映射关系 */
    private final Map<String, List<PartitionInfo>> partitionsByTopic;
    /** 记录 topic 及其分区信息的映射关系（必须包含 leader 副本） */
    private final Map<String, List<PartitionInfo>> availablePartitionsByTopic;
    /** 记录节点 ID 与分区信息的映射关系 */
    private final Map<Integer, List<PartitionInfo>> partitionsByNode;
    /** key 是 brokerId，value 是 broker 节点信息，方便基于 brokerId 获取对应的节点信息 */
    private final Map<Integer, Node> nodesById;

    // ... 省略方法定义

}
```

其中 Node、TopicPartition 和 PartitionInfo 类定义比较简单，其作用分别为：

- Node：封装 kafka 节点信息，包括 ID、主机名，以及端口号等信息。

- TopicPartition：封装分区摘要信息，包含分区所属 topic 和分区编号。

- PartitionInfo：封装分区详细信息，包括分区所属 topic、分区编号、leader 副本所在节点、全部副本所在节点列表，以及 ISR 副本所在节点列表。

继续回到 KafkaProducer#waitOnMetadata 方法。接下来方法会判断是否需要更新集群元数据信息，判断的依据是当前本地缓存的目标 topic 的分区数目不为空，同时如果发送消息时明确指定了分区编号，则此编号必须在本地认为合法的分区编号区间范围内。如果能够满足这些条件，则认为本地缓存的集群信息是合法的，可以直接拿来使用，否则就会触发更新集群元数据的逻辑。如果需要更新集群元数据，则会调用 Metadata#requestUpdate 方法设置标记位，同时唤醒 sender 线程进行处理，并等待集群元数据更新完成。判定更新完成的策略就是判定本地缓存的集群元数据的版本号（Metadata#version 字段）是否被更新，因为集群元数据每更新成功一次，版本号会加 1。如果等待过程超时则会抛出 TimeoutException 异常。

2.基于注册的 key 序列化器对消息的 key 执行序列化；

3.基于注册的 value 序列化器对消息的 value 执行序列化；

4.如果未指定目标 topic 分区，则基于注册的分区器为当前消息计算目标分区；


```java
private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) {
    // 获取当前待发送消息所指定的分区
    Integer partition = record.partition();
    // 如果未指定分区，则为当前消息计算一个分区编号
    return partition != null ?
            partition :
            partitioner.partition(record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);
}
```

如果我们在发送消息时明确指定了分区编号，那么这里只是简单的返回该编号，否则就需要基于注册的分区器计算当前消息对应的分区编号。Partitioner 接口是分区器的抽象，我们可以实现该接口自定义分区器，Kafka 也提供了默认的分区器实现 DefaultPartitioner，分区算法实现如下：

```java
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    // 获取当前 topic 的分区详细信息
    List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
    // 获取当前 topic 对应的分区数
    int numPartitions = partitions.size();
    // 如果没有设置 key，则基于轮询算法
    if (keyBytes == null) {
        // 获取当前 topic 对应的上次位置值加 1，如果是第一次则随机生成一个
        int nextValue = this.nextValue(topic);
        // 获取当前 topic 包含 leader 副本的分区详细信息
        List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);
        if (availablePartitions.size() > 0) {
            int part = Utils.toPositive(nextValue) % availablePartitions.size();
            return availablePartitions.get(part).partition();
        } else {
            // no partitions are available, give a non-available partition
            return Utils.toPositive(nextValue) % numPartitions;
        }
    }
    // 如果指定了 key，则使用 murmur2 算法对 key 做哈希取模
    else {
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }
}
```

默认分区器 DefaultPartitioner 依据消息的 key 计算分区，如果在发送消息时未指定 key，则默认分区器会基于 Round-Robin 算法计算分区编号，以保证目标 topic 分区的负载均衡。否则会基于 32 位的 murmur2 哈希算法计算 key 的哈希值，并与分区数取模得到最后的分区编号。

5.缓存消息到消息收集器 RecordAccumulator 中；

会计算并校验当前消息的大小，同时为消息附加时间戳，并最终调用 RecordAccumulator#append 方法将消息缓存到收集器 RecordAccumulator 中，等待 sender 线程投递给 kafka 集群。RecordAccumulator 是生产者 SDK 中非常重要的一个类，可以将其看做是一个本地缓存消息的队列，消息收集线程将消息最终记录到收集器中，而 sender 线程会定期定量从收集器中取出缓存的消息，并投递给 kafka 集群。RecordAccumulator 类字段定义如下：

```java
public final class RecordAccumulator {

    /** 标识当前收集器是否被关闭，对应 producer 被关闭 */
    private volatile boolean closed;
    /** 记录正在执行 flush 操作的线程数 */
    private final AtomicInteger flushesInProgress;
    /** 记录正在执行 append 操作的线程数 */
    private final AtomicInteger appendsInProgress;
    /** 指定每个 RecordBatch 中 ByteBuffer 的大小 */
    private final int batchSize;
    /** 消息压缩类型 */
    private final CompressionType compression;
    /** 通过参数 linger.ms 指定，当本地消息缓存时间超过该值时，即使消息量未达到阈值也会进行投递 */
    private final long lingerMs;
    /** 生产者重试时间间隔 */
    private final long retryBackoffMs;
    /** 缓存（ByteBuffer）管理工具 */
    private final BufferPool free;
    /** 时间戳工具 */
    private final Time time;
    /** 记录 topic 分区与 RecordBatch 的映射关系，对应的消息都是发往对应的 topic 分区 */
    private final ConcurrentMap<TopicPartition, Deque<RecordBatch>> batches;
    /** 记录未发送完成（即未收到服务端响应）的消息集合 */
    private final IncompleteRecordBatches incomplete;
    /**
     * 消息顺序性保证，
     * 缓存当前待发送消息的目标 topic 分区，防止对于同一个 topic 分区同时存在多个未完成的消息，可能导致消息顺序性错乱
     */
    private final Set<TopicPartition> muted;
    /** 记录 drain 方法批量导出消息时上次的偏移量 */
    private int drainIndex;

    // ... 省略方法定义

}
```

既然 RecordAccumulator 可以看做是一个消息缓存队列，那么这里先了解一下其消息存储的模式。这其中涉及到 RecordAccumulator、RecordBatch、MemoryRecords 和 MemoryRecordsBuilder 4 个类。从上面 RecordAccumulator 类的字段列表中我们看到有一个 ConcurrentMap<TopicPartition, Deque<RecordBatch>> 类型的 batches 字段，这里的 key 对应 topic 的某个分区，而 value 是一个 Deque 类型，其中封装了一批 RecordBatch 对象，这些对象中记录了待发送的消息集合，而这些消息的一个共同点就是都是发往相同的 topic 分区。RecordBatch 类字段定义如下：

```java
public final class RecordBatch {

    /** 当前 RecordBatch 创建的时间戳 */
    final long createdMs;
    /** 当前缓存的消息的目标 topic 分区 */
    final TopicPartition topicPartition;
    /** 标识当前 RecordBatch 发送之后的状态 */
    final ProduceRequestResult produceFuture;
    /** 消息的 Callback 队列，每个消息都对应一个 Callback 对象 */
    private final List<Thunk> thunks = new ArrayList<>();
    /** 用来存储数据的 {@link MemoryRecords} 对应的 builder 对象 */
    private final MemoryRecordsBuilder recordsBuilder;
    /** 发送当前 RecordBatch 的重试次数 */
    volatile int attempts;
    /** 最后一次重试发送的时间戳` */
    long lastAttemptMs;
    /** 记录保存的 record 个数 */
    int recordCount;
    /** 记录最大的 record 字节数 */
    int maxRecordSize;
    /** 记录上次投递当前 BatchRecord 的时间戳 */
    long drainedMs;
    /** 追后一次向当前 RecordBatch 追加消息的时间戳 */
    long lastAppendTime;
    /** 标记是否正在重试 */
    private boolean retry;

    // ... 省略方法定义

}
```

我们可以从字段定义中看到 RecordBatch 持有一个 MemoryRecordsBuilder 类型的字段，MemoryRecordsBuilder 是 MemoryRecords 的构造和管理器，也就是说 RecordBatch 本质上是以 MemoryRecords 作为存储介质。

了解了 RecordAccumulator 类在存储模式上的设计之后，我们接下来分析 RecordAccumulator#append 方法的实现：

```java
public RecordAppendResult append(TopicPartition tp,
                                 long timestamp,
                                 byte[] key,
                                 byte[] value,
                                 Callback callback,
                                 long maxTimeToBlock) throws InterruptedException {
    // 记录正在向收集器中追加消息的线程数
    appendsInProgress.incrementAndGet();
    try {
        // 获取当前 topic 分区对应的 Deque，如果不存在则创建一个
        Deque<RecordBatch> dq = this.getOrCreateDeque(tp);
        synchronized (dq) {
            if (closed) {
                // producer 已经被关闭了，抛出异常
                throw new IllegalStateException("Cannot send after the producer is closed.");
            }
            // 向 Deque 中最后一个 RecordBatch 追加 Record，并返回对应的 RecordAppendResult 对象
            RecordAppendResult appendResult = this.tryAppend(timestamp, key, value, callback, dq);
            if (appendResult != null) {
                // 追加成功，直接返回
                return appendResult;
            }
        }

        /* 追加 Record 失败，尝试申请新的 buffer */

        int size = Math.max(this.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));
        log.trace("Allocating a new {} byte message buffer for topic {} partition {}", size, tp.topic(), tp.partition());
        // 申请新的 buffer
        ByteBuffer buffer = free.allocate(size, maxTimeToBlock);
        synchronized (dq) {
            if (closed) {
                // 再次校验 producer 状态，如果已经被关闭了，抛出异常
                throw new IllegalStateException("Cannot send after the producer is closed.");
            }

            // 再次尝试向 Deque 中最后一个 RecordBatch 追加 Record
            RecordAppendResult appendResult = this.tryAppend(timestamp, key, value, callback, dq);
            if (appendResult != null) {
                // 追加成功则返回，同时归还之前申请的 buffer
                free.deallocate(buffer);
                return appendResult;
            }

            /* 仍然追加失败，创建一个新的 RecordBatch 进行追加 */

            MemoryRecordsBuilder recordsBuilder = MemoryRecords.builder(buffer, compression, TimestampType.CREATE_TIME, this.batchSize);
            RecordBatch batch = new RecordBatch(tp, recordsBuilder, time.milliseconds());
            // 在新创建的 RecordBatch 中追加 Record
            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));
            dq.addLast(batch);
            // 追加到未完成的集合中
            incomplete.add(batch);
            // 封装成 RecordAppendResult 对象返回
            return new RecordAppendResult(future, dq.size() > 1 || batch.isFull(), true);
        }
    } finally {
        appendsInProgress.decrementAndGet();
    }
}
```

追加消息到收集器的过程首先会获取指定 topic 分区对应的发送队列，如果不存在则会创建一个。然后同步往该队列的最后一个 RecordBatch 对象中追加数据，追加的过程位于 RecordAccumulator#tryAppend 方法中。如果追加失败，一般都是因为该 RecordBatch 没有足够的空间足以容纳，则方法会尝试申请新的空间，然后继续尝试追加。如果还是失败，则方法会创建一个新的 RecordBatch 对象进行追加。整个过程多次调用到 RecordAccumulator#tryAppend 方法，下面来看一下该方法的实现：

```java
private RecordAppendResult tryAppend(long timestamp, byte[] key, byte[] value, Callback callback, Deque<RecordBatch> deque) {
    // 获取 deque 的最后一个 RecordBatch
    RecordBatch last = deque.peekLast();
    if (last != null) {
        // 尝试往该 RecordBatch 末尾追加消息
        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, callback, time.milliseconds());
        if (future == null) {
            // 追加失败
            last.close();
        } else {
            // 追加成功，将结果封装成 RecordAppendResult 对象返回
            return new RecordAppendResult(future, deque.size() > 1 || last.isFull(), false);
        }
    }
    return null;
}

// org.apache.kafka.clients.producer.internals.RecordBatch#tryAppend
public FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value, Callback callback, long now) {
    // 检测是否还有多余的空间容纳该消息
    if (!recordsBuilder.hasRoomFor(key, value)) {
        // 没有多余的空间则直接返回，后面会尝试申请新的空间
        return null;
    }
    // 添加当前消息到 MemoryRecords，并返回消息对应的 CRC32 校验码
    long checksum = this.recordsBuilder.append(timestamp, key, value);
    // 更新最大 record 字节数
    this.maxRecordSize = Math.max(this.maxRecordSize, Record.recordSize(key, value));
    // 更新最后一次追加记录时间戳
    this.lastAppendTime = now;
    FutureRecordMetadata future = new FutureRecordMetadata(
            produceFuture, recordCount,
            timestamp, checksum,
            key == null ? -1 : key.length,
            value == null ? -1 : value.length);
    if (callback != null) {
        // 如果指定了 Callback，将 Callback 和 FutureRecordMetadata 封装到 Trunk 中
        thunks.add(new Thunk(callback, future));
    }
    this.recordCount++;
    return future;
}
```

上面过程最终调用 MemoryRecordsBuilder#append 方法将消息追加到 MemoryRecords 相应的位置进行存储，并返回消息的 CRC32 校验码，至于 MemoryRecords 存储消息的细节这里不再继续深入。消息追加成功之后，如果在发送消息时指定了 Callback 函数，那么这里会将其封装成 Thunk 类对象，至于其作用这里先不展开分析，等到后面分析 sender 线程的执行过程时再一探究竟，这里初步猜测 sender 线程在向集群投递完消息并收到来自集群的响应时，会循环遍历 thunks 集合，并应用 Callback 对应的回调方法。

6.条件性唤醒消息发送线程。上面追加的过程会返回一个 RecordAppendResult 对象，该对象通过 RecordAppendResult#batchIsFull 和 RecordAppendResult#newBatchCreated 两个字段分别标记了追加过程中末端的 RecordBatch 是否已满，以及追加过程中是否有创建新的 RecordBatch 对象，如果这两个条件满足其中之一，则会唤醒 sender 线程尝试向集群投递收集的消息数据。

#### 投递待发送的消息

前面曾提出一个概念，即客户端发送消息的过程实际上是一个异步的过程，由 2 个线程协同执行，其中 1 个线程将待发送的消息写入缓冲区，另外 1 个线程（Sender 线程）负责定期定量将缓冲区中的数据投递给远端 kafka 集群，并反馈投递结果。上面我们分析了过程 1，下面我们继续分析过程 2，即将缓存的消息发送给 kafka 集群。

这一过程由 sender 线程负责执行，前面的分析中曾多次唤醒过该线程，下面来看一下其实现，位于 Sender 类中，该类实现了 java.lang.Runnable 接口，其 Sender#run 方法实现如下：

```java
public void run() {

    // 主循环，一直运行直到 KafkaProducer 被关闭
    while (running) {
        try {
            this.run(time.milliseconds());
        } catch (Exception e) {
            log.error("Uncaught error in kafka producer I/O thread: ", e);
        }
    }

    /* 如果 KafkaProducer 被关闭，尝试发送剩余的消息 */
    while (!forceClose // 不是强制关闭
            // 存在未发送或已发送待响应的请求
            && (this.accumulator.hasUnsent() || this.client.inFlightRequestCount() > 0)) {
        try {
            this.run(time.milliseconds());
        } catch (Exception e) {
            log.error("Uncaught error in kafka producer I/O thread: ", e);
        }
    }

    // 如果是强制关闭，忽略所有未发送和已发送待响应的请求
    if (forceClose) {
        // 丢弃所有未发送完成的消息
        this.accumulator.abortIncompleteBatches();
    }
    try {
        // 关闭网络连接
        this.client.close();
    } catch (Exception e) {
        log.error("Failed to close network client", e);
    }
}
```

由上述方法实现可知，Sender 线程在启动后会一直循环执行另外一个重载版本的 Sender#run 方法，其中包含了 sender 线程的主要逻辑。如果客户端被关闭（一般都是调用 KafkaProducer#close 方法），在不是强制关闭的前提下，Sender 线程会继续处理本地未发送和已发送但未收到服务端确认的消息，如果是强制关闭（在调用 KafkaProducer#close 方法时允许指定超时等待时间，如果在既定时间内客户端仍未完成对缓存消息的处理，则会触发强制关闭机制），则会丢弃本地缓存的所有未发送的消息，最后关闭到 kafka 集群的网络连接。

下面来看一下 sender 线程的核心实现，即重载版本的 Sender#run 方法：

```java
void run(long now) {

    // 1. 计算需要以及可以向哪些节点发送请求
    Cluster cluster = metadata.fetch(); // 获取 kafka 集群信息
    RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(cluster, now); // 计算需要向哪些节点发送请求

    // 2. 如果存在未知的 leader 副本对应的节点（对应的 topic 分区正在执行 leader 选举，或者对应的 topic 已经失效），标记需要更新缓存的集群元数据信息
    if (!result.unknownLeaderTopics.isEmpty()) {
        for (String topic : result.unknownLeaderTopics) this.metadata.add(topic);
        this.metadata.requestUpdate();
    }

    // 3. 遍历处理待发送请求的目标节点，基于网络 IO 检查对应节点是否可用，对于不可用的节点则剔除
    Iterator<Node> iter = result.readyNodes.iterator();
    long notReadyTimeout = Long.MAX_VALUE;
    while (iter.hasNext()) {
        Node node = iter.next();
        // 检查目标节点是否准备好接收请求，如果未准备好但目标节点允许创建连接，则创建到目标节点的连接
        if (!this.client.ready(node, now)) {
            // 对于未准备好的节点，则从 ready 集合中删除
            iter.remove();
            notReadyTimeout = Math.min(notReadyTimeout, this.client.connectionDelay(node, now));
        }
    }

    // 4. 获取每个节点待发送消息集合，其中 key 是目标 leader 副本所在节点 ID
    Map<Integer, List<RecordBatch>> batches =
            this.accumulator.drain(cluster, result.readyNodes, this.maxRequestSize, now);

    // 5. 如果需要保证消息的强顺序性，则缓存对应 topic 分区对象，防止同一时间往同一个 topic 分区发送多条处于未完成状态的消息
    if (guaranteeMessageOrder) {
        // 将所有 RecordBatch 的 topic 分区对象加入到 muted 集合中
        // 防止同一时间往同一个 topic 分区发送多条处于未完成状态的消息
        for (List<RecordBatch> batchList : batches.values()) {
            for (RecordBatch batch : batchList)
                this.accumulator.mutePartition(batch.topicPartition);
        }
    }

    // 6. 处理本地过期的消息，返回 TimeoutException，并释放空间
    List<RecordBatch> expiredBatches = this.accumulator.abortExpiredBatches(this.requestTimeout, now);

    // 如果存在待发送的消息，则设置 pollTimeout 等于 0，这样可以立即发送请求，从而能够缩短剩余消息的缓存时间，避免堆积
    long pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);
    if (!result.readyNodes.isEmpty()) {
        log.trace("Nodes with data ready to send: {}", result.readyNodes);
        pollTimeout = 0;
    }

    // 7. 发送请求到服务端，并处理服务端响应
    this.sendProduceRequests(batches, now);
    this.client.poll(pollTimeout, now);
}
```